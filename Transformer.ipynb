{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjYI62rpKNxS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "# os.environ['TRANSFORMERS_CACHE'] = '/content/drive/MyDrive/LLM'\n",
        "# os.environ['HF_DATASETS_CACHE'] = '/content/drive/MyDrive/LLM'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZaH4X3mMiMy",
        "outputId": "94dc9c46-5a27-4b0b-8220-42f3c71ab3fe"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiLG3r3SDgOg"
      },
      "source": [
        "### Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbsXgLF2KTnX"
      },
      "outputs": [],
      "source": [
        "# Setup libs\n",
        "!pip -q install bitsandbytes accelerate xformers einops langchain faiss-cpu transformers sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140,
          "referenced_widgets": [
            "888058cde48344a1a8af09b5c996c40f",
            "63e1903c685a488eadc99688eafa6046",
            "4a7f3ecb3d3b462196546dce0652b805",
            "6555e5bdcf1c42ec8a791abd584220c0",
            "1b0f57450b8e4ca08156dbfe8e8b59ac",
            "5ec9c8c586554cbaad4e9391a7af3e50",
            "79c0050183f34597af664063bd718aaf",
            "2fbc8b96d1f54226a27887e2ce95df37",
            "de076a519a38456f893de2809feac844",
            "8484c2c0957b4138a6563aff7ba77d5f",
            "779eac2815ca44669afac6cd5ea334de"
          ]
        },
        "id": "WSolLJx01qIA",
        "outputId": "e084e9e6-2ccb-44d1-b626-948d348aa3db"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig,pipeline,BitsAndBytesConfig\n",
        "\n",
        "model_path = \"mistralai/Mistral-7B-v0.3\" # c'est juste une exemple \n",
        "token=\"Votre_token_Huggingface\"\n",
        "\n",
        "\n",
        "# Setup le tokeniseur\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True, token=token)\n",
        "\n",
        "\n",
        "# Parametrer la config\n",
        "config = AutoConfig.from_pretrained(model_path, trust_remote_code=True, token=token)\n",
        "config.init_device = \"cuda\"\n",
        "config.temperature = 0.1\n",
        "# config.max_length =300\n",
        "# config.eos_token_id=tokenizer.eos_token_id\n",
        "# config.pad_token_id=tokenizer.pad_token_id\n",
        "# config.do_sample = True\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "                                load_in_4bit=True,\n",
        "                                bnb_4bit_use_double_quant=True,\n",
        "                                bnb_4bit_quant_type=\"nf4\",\n",
        "                                bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "                               )\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,quantization_config=bnb_config,\n",
        "    config=config,\n",
        "    trust_remote_code=True , token=token\n",
        ")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# pipe = pipeline('text-generation', model=model, tokenizer=tokenizer)#, device=0,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTF1yO7XDjnv"
      },
      "source": [
        "### Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hY8xB6LO6hCW"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain sentence-transformers openai tiktoken faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67C2mZOYg3m-"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "text_generation_pipeline = transformers.pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"text-generation\",\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    repetition_penalty=1.1,\n",
        "    return_full_text=True,\n",
        "    max_new_tokens=100,\n",
        ")\n",
        "my_pipeline = HuggingFacePipeline(pipeline=text_generation_pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "u1vhg8vD2R3n",
        "outputId": "1a9756f8-dc5f-464c-9528-2280f914c506"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"### Question:\\n{instruction}\\n\\n### Répondre:\"\n",
        "\n",
        "input_prompt = PROMPT.format_map(\n",
        "    {\"instruction\": \"Combien de types de fruits existe-t-il ?\"}\n",
        ")\n",
        "my_pipeline(input_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKWeuNTeo2XZ"
      },
      "outputs": [],
      "source": [
        "# Creer Prompt template\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "template = \"### Question:\\n{question}\\n\\n### Répondre:\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebZ6XrsAiFCX",
        "outputId": "3142d3b7-afc8-4252-de88-f6566ae8399e"
      },
      "outputs": [],
      "source": [
        "from langchain import LLMChain\n",
        "llm_chain = LLMChain(prompt=prompt,\n",
        "                     llm=my_pipeline\n",
        "                     )\n",
        "\n",
        "question = \"Combien de côtés a un triangle ?\"\n",
        "\n",
        "result = llm_chain.run({\"question\":question})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS4QksY8HKiN"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "def get_text_chunks(text):\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len\n",
        "    )\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCyM8gkzHwAl"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7dODIP0nnDq",
        "outputId": "5e62bfe9-5d36-423f-82bd-fe9be3b1e525"
      },
      "outputs": [],
      "source": [
        "!pip -q install InstructorEmbedding gpt4all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW7P09ODI0UQ",
        "outputId": "a1b2ecab-59db-4ad8-d1c3-9a3a180e7767"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings, HuggingFaceEmbeddings\n",
        "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings, GPT4AllEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "embeddings = GPT4AllEmbeddings()#OpenAIEmbeddings()#HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\")\n",
        "#HuggingFaceEmbeddings(model_name=model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0xRjSqZHO6c"
      },
      "outputs": [],
      "source": [
        "raw_text =\"\"\"\n",
        "Votre Text 1\n",
        "\"\"\"\n",
        "raw_text =\"\"\"\n",
        "Votre Text 2\n",
        "\"\"\"\n",
        "# obtenir les morceaux de texte\n",
        "text_chunks = get_text_chunks(raw_text)\n",
        "\n",
        "# creer vecteur store\n",
        "#vectorstore = get_vectorstore(text_chunks)\n",
        "vectorstore = FAISS.from_texts(texts=text_chunks, embedding=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBbuyU_LKdrh"
      },
      "outputs": [],
      "source": [
        "db = vectorstore.as_retriever(search_kwargs={'k': 3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMSUR2wQnfFT"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "template_qa = \"Utilisez le contexte suivant pour répondre à la question\\n{context}\\n### Question:\\n{question}\\n\\n### Répondre:\"\n",
        "prompt_qa = PromptTemplate(template=template_qa, input_variables=[\"question\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUIo0l0CiqOw"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "template = prompt = \"\"\"<|im_start|>system\n",
        "Utilisez le contexte suivant pour répondre à la question\\n{context}\\n\n",
        "<|im_end|>\n",
        "<|im_start|>user\n",
        "{question}<|im_end|>\n",
        "<|im_start|>assistant\"\"\"\n",
        "\n",
        "prompt_qa = PromptTemplate(template=template, input_variables=[\"question\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUEsNKwtKHyJ"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n",
        "\n",
        "qa_chain = RetrievalQA.from_llm(llm=mistral_llm,\n",
        "                                      retriever=db,\n",
        "                                       return_source_documents=True,verbose=True,\n",
        "                                prompt = prompt_qa\n",
        "                                        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHNfXv6IKpY0",
        "outputId": "60fe9ccd-a6d6-491f-ef4a-01e121ea6e1c"
      },
      "outputs": [],
      "source": [
        "query = \"La question est en rapport avec votre texte\"\n",
        "\n",
        "sol=qa_chain({\"query\": query})\n",
        "print(sol)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxrrrNkUYak6"
      },
      "outputs": [],
      "source": [
        "print(qa_chain.combine_documents_chain.llm_chain.prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULQGGYABLQ1F"
      },
      "source": [
        "\n",
        "### Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cl6Tthl47uwd"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "template_qah = \"Utilisez le contexte suivant pour répondre à la question\\n{context}\\net historique\\n{chat_history}\\n### Question:\\n{question}\\n\\n### Répondre:\"\n",
        "prompt_qah = PromptTemplate(template=template_qah, input_variables=[\"question\"])\n",
        "\n",
        "template_qah_1 = \"Historique:\\n{chat_history}\\n### Question:\\n{question}\\n\\n### Répondre:\"\n",
        "prompt_qah_1 = PromptTemplate(template=template_qah_1, input_variables=[\"question\"])\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n",
        "\n",
        "qah_chain = ConversationalRetrievalChain.from_llm(llm=hf_pipeline,\n",
        "                                      retriever=db,\n",
        "                                       return_source_documents=False,verbose=True,\n",
        "                                 memory = memory,combine_docs_chain_kwargs={'prompt': prompt_qah},\n",
        "     condense_question_prompt=prompt_qah_1,\n",
        "                                        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqoWtPPF8V2m"
      },
      "outputs": [],
      "source": [
        "query = \"La question est en rapport avec votre texte\"\n",
        "\n",
        "sol=qah_chain({\"question\": query})\n",
        "print(sol)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1b0f57450b8e4ca08156dbfe8e8b59ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fbc8b96d1f54226a27887e2ce95df37": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a7f3ecb3d3b462196546dce0652b805": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fbc8b96d1f54226a27887e2ce95df37",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de076a519a38456f893de2809feac844",
            "value": 0
          }
        },
        "5ec9c8c586554cbaad4e9391a7af3e50": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63e1903c685a488eadc99688eafa6046": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ec9c8c586554cbaad4e9391a7af3e50",
            "placeholder": "​",
            "style": "IPY_MODEL_79c0050183f34597af664063bd718aaf",
            "value": "Loading checkpoint shards:   0%"
          }
        },
        "6555e5bdcf1c42ec8a791abd584220c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8484c2c0957b4138a6563aff7ba77d5f",
            "placeholder": "​",
            "style": "IPY_MODEL_779eac2815ca44669afac6cd5ea334de",
            "value": " 0/2 [00:00&lt;?, ?it/s]"
          }
        },
        "779eac2815ca44669afac6cd5ea334de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79c0050183f34597af664063bd718aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8484c2c0957b4138a6563aff7ba77d5f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "888058cde48344a1a8af09b5c996c40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63e1903c685a488eadc99688eafa6046",
              "IPY_MODEL_4a7f3ecb3d3b462196546dce0652b805",
              "IPY_MODEL_6555e5bdcf1c42ec8a791abd584220c0"
            ],
            "layout": "IPY_MODEL_1b0f57450b8e4ca08156dbfe8e8b59ac"
          }
        },
        "de076a519a38456f893de2809feac844": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
